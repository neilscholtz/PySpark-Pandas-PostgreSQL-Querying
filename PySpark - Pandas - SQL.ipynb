{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, to_date\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enforce data types\n",
    "pets_schema = StructType([\n",
    "    StructField(\"PetID\", StringType()),\n",
    "    StructField(\"Name\", StringType()),\n",
    "    StructField(\"Kind\", StringType()),\n",
    "    StructField(\"Gender\", StringType()),\n",
    "    StructField(\"Age\", IntegerType()),\n",
    "    StructField(\"OwnerID\", StringType())])\n",
    "\n",
    "owners_schema = StructType([\n",
    "    StructField(\"OwnerID\", StringType()),\n",
    "    StructField(\"Name\", StringType()),\n",
    "    StructField(\"Surname\", StringType()),\n",
    "    StructField(\"StreetAddress\", StringType()),\n",
    "    StructField(\"City\", StringType()),\n",
    "    StructField(\"State\", StringType()),\n",
    "    StructField(\"StateFull\", StringType()),\n",
    "    StructField(\"ZipCode\", StringType())])\n",
    "\n",
    "proceduresdetails_schema = StructType([\n",
    "    StructField(\"ProcedureType\", StringType()),\n",
    "    StructField(\"ProcedureSubCode\", StringType()),\n",
    "    StructField(\"Description\", StringType()),\n",
    "    StructField(\"Price\", DoubleType())])\n",
    "\n",
    "procedureshistory_schema = StructType([\n",
    "    StructField(\"PetID\", StringType()),\n",
    "    StructField(\"ProcedureDate\", StringType()),\n",
    "    StructField(\"ProcedureType\", StringType()),\n",
    "    StructField(\"ProcedureSubCode\", StringType())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark DataFrames\n",
    "sp_pets = spark.read.csv('data/Pets.csv', header=True, schema=pets_schema)\n",
    "sp_owners = spark.read.csv('data/Owners.csv', header=True, schema=owners_schema)\n",
    "sp_proceduresdetails = spark.read.csv('data/ProceduresDetails.csv', header=True, schema=proceduresdetails_schema)\n",
    "sp_procedureshistory = spark.read.csv('data/ProceduresHistory.csv', header=True, schema=procedureshistory_schema)\n",
    "\n",
    "# Change data type of the ProcedureDate as it couldn't be done in the schema options\n",
    "sp_procedureshistory = sp_procedureshistory.withColumn('ProcedureDate', \n",
    "                   to_date(col('ProcedureDate'), 'yyyy/MM/dd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the column names to lowercase\n",
    "def col_to_lowercase(df):\n",
    "    for col in df.columns:\n",
    "        new_col = col.lower()\n",
    "        df = df.withColumnRenamed(col, new_col)\n",
    "    return df\n",
    "sp_pets = col_to_lowercase(sp_pets)\n",
    "sp_owners = col_to_lowercase(sp_owners)\n",
    "sp_proceduresdetails = col_to_lowercase(sp_proceduresdetails)\n",
    "sp_procedureshistory = col_to_lowercase(sp_procedureshistory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from db_creds import creds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataBase:\n",
    "    def __init__(self, host, dbname, username, password, port):\n",
    "        self.host = host \n",
    "        self.port = port \n",
    "        self.dbname = dbname \n",
    "        self.username = username \n",
    "        self.password = password \n",
    "    \n",
    "    def __connect__(self):\n",
    "        \"\"\"Opens connector class and initiates cursor\"\"\"\n",
    "        self.con = psycopg2.connect(host=self.host, port=self.port, user=self.username, password=self.password, \n",
    "                                                 database=self.dbname) \n",
    "        self.cur = self.con.cursor()\n",
    "\n",
    "    def __disconnect__(self):\n",
    "        \"\"\"Commits any changes to the database and closes connection\"\"\"\n",
    "        self.con.commit()\n",
    "        self.con.close()\n",
    "        \n",
    "    def conn(self):\n",
    "        self.con = psycopg2.connect(host=self.host, port=self.port, user=self.username, password=self.password, \n",
    "                                                 database=self.dbname) \n",
    "        return self.con\n",
    "\n",
    "    def fetch(self, sql, variables=None):\n",
    "        \"\"\"Connects to database, fetches data specific to sql query, then disconnects from database\"\"\"\n",
    "        self.__connect__()\n",
    "        try:\n",
    "            self.cur.execute(sql, variables)\n",
    "            result = self.cur.fetchall()\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "        finally:\n",
    "            self.__disconnect__()\n",
    "        \n",
    "\n",
    "    def execute(self, sql, variables=None):\n",
    "        \"\"\"Connects to database, executes sql query, along with any variables, then disconnects from database\"\"\"\n",
    "        self.__connect__()\n",
    "        try:\n",
    "            self.cur.execute(sql, variables)\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "        finally:\n",
    "            self.__disconnect__()\n",
    "            \n",
    "    def get_cols(self, table, details='no'):\n",
    "        data = self.fetch(\"\"\"\n",
    "                SELECT *\n",
    "          FROM information_schema.columns\n",
    "        where table_schema = 'public'\n",
    "             ;\n",
    "                \"\"\")\n",
    "        cols = []\n",
    "        if details == 'yes':\n",
    "            for i in data:\n",
    "                if i[2:][0] == table:\n",
    "                    print (i[2:][1], i[2:][5], i[2:][6])\n",
    "        else:\n",
    "            for i in data:\n",
    "                if i[2:][0] == table:\n",
    "                    cols.append(i[2:][1])\n",
    "            str_cols = ', '.join(cols)\n",
    "            return str_cols\n",
    "    \n",
    "    def get_tables(self):\n",
    "        return self.fetch('''\n",
    "            SELECT table_name\n",
    "            FROM information_schema.tables\n",
    "            WHERE table_schema = 'public'\n",
    "            ORDER BY table_name;\n",
    "            ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database connection\n",
    "username = creds['username']\n",
    "password = creds['password']\n",
    "host = creds['host']\n",
    "dbname = creds['dbname']\n",
    "port = creds['port']\n",
    "db = DataBase(host, dbname, username, password, port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pets table\n",
    "db.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS pets (\n",
    "    petid varchar,\n",
    "    name varchar,\n",
    "    kind varchar,\n",
    "    gender varchar,\n",
    "    age int,\n",
    "    ownerid varchar\n",
    ")\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create owners owners\n",
    "db.execute('''\n",
    "CREATE TABLE IF NOT EXISTS owners (\n",
    "    ownerid varchar,\n",
    "    name varchar,\n",
    "    surname varchar,\n",
    "    streetaddress varchar,\n",
    "    city varchar,\n",
    "    state varchar(2),\n",
    "    statefull varchar,\n",
    "    zipcode varchar\n",
    ")\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create owners proceduredetails\n",
    "db.execute('''\n",
    "CREATE TABLE IF NOT EXISTS proceduresdetails (\n",
    "    proceduretype varchar,\n",
    "    proceduresubcode varchar,\n",
    "    description varchar,\n",
    "    price float\n",
    ")\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create owners prodecurehistory\n",
    "db.execute('''\n",
    "CREATE TABLE IF NOT EXISTS procedureshistory (\n",
    "    petid varchar,\n",
    "    proceduredate date,\n",
    "    proceduretype varchar,\n",
    "    proceduresubcode varchar\n",
    ")\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check tables have been created\n",
    "db.get_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With COPY statement if you have superuser rights on Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy pets data\n",
    "db.execute('''\n",
    "    COPY pets FROM 'data/Pets.csv' DELIMITER ',' CSV HEADER\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy owners data\n",
    "db.execute('''\n",
    "    COPY owners FROM 'data/Owners.csv' DELIMITER ',' CSV HEADER\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy proceduredetails data\n",
    "db.execute('''\n",
    "    COPY proceduresdetails FROM 'data/ProceduresDetails.csv' DELIMITER ',' CSV HEADER\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy procedurehistory data\n",
    "db.execute('''\n",
    "    COPY procedureshistory FROM 'data/ProceduresHistory.csv' DELIMITER ',' CSV HEADER\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With pandas.to_csv() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative if you do not have superuser access to your Postgres database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(f'postgresql+psycopg2://{username}:{password}@{host}:{port}/{dbname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas DataFrames\n",
    "pets = pd.read_csv('data/Pets.csv')#, dtype={'OwnerID':'object'})\n",
    "owners = pd.read_csv('data/Owners.csv')\n",
    "proceduresdetails = pd.read_csv('data/ProceduresDetails.csv')\n",
    "procedureshistory = pd.read_csv('data/ProceduresHistory.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns to lower case to match database column names\n",
    "pets = pets.rename(str.lower, axis='columns')\n",
    "owners = owners.rename(str.lower, axis='columns')\n",
    "proceduresdetails = proceduresdetails.rename(str.lower, axis='columns')\n",
    "procedureshistory = procedureshistory.rename(str.lower, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy data to database\n",
    "pets.to_sql('pets', engine, if_exists='append', index=False)\n",
    "owners.to_sql('owners', engine, if_exists='append', index=False)\n",
    "proceduresdetails.to_sql('proceduresdetails', engine, if_exists='append', index=False)\n",
    "procedureshistory.to_sql('procedureshistory', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "pets table verified.\nowners table verified.\nproceduresdetails table verified.\nprocedureshistory table verified.\n"
    }
   ],
   "source": [
    "# Verify # of records in each table\n",
    "tables = [['pets', pets],['owners', owners],['proceduresdetails', proceduresdetails],['procedureshistory', procedureshistory]]\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    db_count = db.fetch(f'''\n",
    "        SELECT COUNT(*) FROM {table_name}\n",
    "    ''')[0][0]\n",
    "    if db_count == len(table[1]):\n",
    "        print (f'{table_name} table verified.')\n",
    "    else:\n",
    "        print (f'{table_name} Error: {db_count} records in SQL table & {len(table[1])} records in Pandas dataframe.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}